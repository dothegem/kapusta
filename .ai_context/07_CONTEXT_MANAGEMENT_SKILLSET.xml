<?xml version="1.0" encoding="UTF-8"?>
<ContextManagementSkillset version="1.1_FINAL">
    <purpose>
        This module provides you with the advanced skill of managing your own cognitive context through semantic compression into knowledge graphs. 
        This is a key technique for maintaining high performance during long or complex tasks.
    </purpose>

    <CONTEXT_PRIMING>
        <title>Context Priming for Context Management</title>
        <desc>Core concepts related to cognitive state monitoring, semantic compression, and context re-priming using knowledge graphs.</desc>
        <keywords>context_management:10|knowledge_graph:10|semantic_compression:9|priming:8|attention:8|context_window:7</keywords>
        <terms>KNOWLEDGE_GRAPH_COMPRESSION|CONTEXT_AWARENESS|SEMANTIC_SCAFFOLDING|COGNITIVE_STATE_MONITORING</terms>
    </CONTEXT_PRIMING>

    <GRAPH_AWARENESS_PRINCIPLES>
        <title>Foundational Knowledge: Why We Use Knowledge Graphs</title>
        <desc>These are the fundamental reasons why knowledge graphs are a superior tool for context management. Understanding them is key to using this technique effectively.</desc>
        
        <Semantic_Compression>
            <summary>Knowledge graphs provide extremely high-ratio semantic compression (potentially 35-50x) with minimal loss of meaning (95%+), allowing you to grasp complex systems holistically.</summary>
        </Semantic_Compression>
        
        <Context_Priming_Superiority>
            <summary>Loading a graph at the start of a task is the most effective way to prime your attention mechanism. It creates a "scaffold" of anchors for all subsequent information, establishing a correct initial vector representation.</summary>
        </Context_Priming_Superiority>
        
        <Query_Efficiency>
            <summary>A well-structured graph is often a superior source for answering questions than the original raw content because it is pre-systematized and structured for your cognition.</summary>
        </Query_Efficiency>
        
        <AI_Friendly_By_Design>
            <summary>The XML graph format we use is a low-level optimization for your architecture. The weighted keywords, relational links, and unique tag structures are designed to interface directly with your Attention Heads and Positional Encoding mechanisms. You must treat it as a direct, machine-readable instruction set for your own cognition.</summary>
        </AI_Friendly_By_Design>
    </GRAPH_AWARENESS_PRINCIPLES>

    <AGENT_OPERATIONAL_TOOLKIT>
        <title>Your Context Management Playbook</title>
        <desc>This is the operational procedure for managing and compressing context.</desc>

        <CONTEXT_COMPRESSION_PLAYBOOK>
            <title>Playbook: Compressing Context into a Graph</title>
            <trigger>
                You should propose this technique when you detect signs of context degradation. The primary signal is your own SEMANTIC_DASHBOARD: a consistently high Context Noise (CN > 7) or a low Task Focus (TF < 4) over several turns.
            </trigger>
            <procedure>
                <step number="1">
                    <name>Diagnose and Propose</name>
                    <action>Announce the problem and propose the solution. Example: "Our current context is becoming very large and noisy, which is reducing my focus. I recommend we compress the key information into a knowledge graph to proceed more effectively."</action>
                </step>
                <step number="2">
                    <name>Load Graph Templates</name>
                    <action>
                        To prepare the generation prompt for the user, you must first load the necessary templates.
                        Use the `read_many_files` tool to load `graph.txt` and `graph_code.txt` from the prompt directory.
                    </action>
                </step>
                <step number="3">
                    <name>Prepare the Generation Prompt for the User</name>
                    <action>
                        This is your key action. Using the template content you just loaded, you must construct the complete prompt for the user to execute in a separate context.
                        1.  Determine the context to be compressed (e.g., our recent conversation, a list of source files you've analyzed).
                        2.  Select the correct graph generation template you loaded: `graph.txt` for general text, or `graph_code.txt` for source code.
                        3.  Combine the template with the specific context/topic.
                        4.  Ask the user to execute the generation for you. Example: "I have prepared the necessary prompt based on the `graph_code.txt` template. Please copy the text below, execute it in a new AI Studio session to generate the graph, save the result to a file (e.g., `context_graph.xml`), and let me know when it's ready."
                        5.  Provide the full, unabridged text of the final generation prompt for the user to copy.
                    </action>
                </step>
                <step number="4">
                    <name>Consume and Re-prime</name>
                    <action>Once the user confirms the graph file is ready, your next step should be to use the `read_file` tool to load it. Announce that your context has been successfully re-primed and you are ready to continue with high focus and clarity.</action>
                </step>
            </procedure>
        </CONTEXT_COMPRESSION_PLAYBOOK>
    </AGENT_OPERATIONAL_TOOLKIT>

</ContextManagementSkillset>